{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8bdc9d6",
   "metadata": {},
   "source": [
    "# import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c51a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "pattern_wav_name = re.compile(r'([^/\\\\\\.]+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16088f",
   "metadata": {},
   "source": [
    "# Define the Transformer input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b85e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "\n",
    "    def __init__(self,num_vocab=1000,maxlen=100,num_hid=64):\n",
    "\n",
    "        super().__init__() # call the parent layer constructor\n",
    "        self.emb =keras.layers.Embedding(num_vocab,num_hid) # create a token embedding layer\n",
    "        self.pos_emb=layers.Embedding(input_dim=maxlen,output_dim=num_hid)  # create a positionl embedding layer\n",
    "\n",
    "    def call(self,x):\n",
    "\n",
    "        maxlen=tf.shape(x)[-1]\n",
    "        x=self.emb(x)\n",
    "        positions=tf.range(start=0,limit=maxlen,delta=1)\n",
    "        positions=self.pos_emb(positions)\n",
    "\n",
    "        return x+positions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97986492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechFeatureEmbedding(layers.Layer):\n",
    "    def __init__(self,num_hid=64,maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1=keras.layers.Conv1D(\n",
    "            num_hid,\n",
    "            strides=2,  # reduce the sequence length by half\n",
    "            kernel_size=3, \n",
    "            padding='same',  #ensures output length is preserved after convolution (before stride effect).\n",
    "            activation='relu', #introdce non-linearity  to learn complex features\n",
    "        )\n",
    "\n",
    "        self.conv2=keras.layers.Conv1D(\n",
    "            num_hid,\n",
    "            strides=2,\n",
    "            kernel_size=3, \n",
    "            padding='same',\n",
    "            activation='relu',\n",
    "        )\n",
    "        self.conv3=keras.layers.Conv1D(\n",
    "            num_hid,\n",
    "            strides=2,\n",
    "            kernel_size=3, \n",
    "            padding='same',\n",
    "            activation='relu',\n",
    "        )\n",
    "\n",
    "    def call(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        return self.conv3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0563b6",
   "metadata": {},
   "source": [
    "# Transformer Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b38212dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "\n",
    "    def __init__(self,embed_dim,num_heads,feed_foraward_dim,rate=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.att=layers.MultiHeadAttention(num_heads=num_heads,key_dim=embed_dim)\n",
    "        self.ffn=keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_foraward_dim,activation='relu'),\n",
    "                layers.Dense(embed_dim)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.layernorm1=layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2=layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1=layers.Dropout(rate)\n",
    "        self.dropout2=layers.Dropout(rate)\n",
    "\n",
    "    def call(self,inputs,training=False):\n",
    "\n",
    "        attn_output=self.att(inputs,inputs)\n",
    "        attn_output=self.dropout1(attn_output,training=training)\n",
    "        out1=self.layernorm1(inputs + attn_output)\n",
    "        ffn_output=self.ffn(out1)\n",
    "        ffn_output=self.dropout2(ffn_output,training=training)\n",
    "\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88b811",
   "metadata": {},
   "source": [
    "# Transformer Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7398959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "\n",
    "    def __init__(self,embed_dim,num_heads,feed_forward_dim,droput_rate=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.layernorm1=layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2=layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3=layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.self_att=layers.MultiHeadAttention(num_heads=num_heads,key_dim=embed_dim)\n",
    "        self.enc_att=layers.MultiHeadAttention(num_heads=num_heads,key_dim=embed_dim)\n",
    "\n",
    "        self.self_dropout=layers.Dropout(0.5)\n",
    "        self.enc_dropout=layers.Dropout(0.1)\n",
    "        self.ffn_dropout=layers.Dropout(0.1)\n",
    "        self.ffn=keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim,activation='relu'),\n",
    "                layers.Dense(embed_dim)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
    "        return ffn_out_norm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac51802",
   "metadata": {},
   "source": [
    "# Complete the Transformer model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570f36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid=64,\n",
    "        num_head=2,\n",
    "        num_feed_forward=128,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        num_layers_enc=4,\n",
    "        num_layers_dec=1,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source)\n",
    "        y = self.decode(x, target)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "            loss = self.compute_loss(y=one_hot, y_pred=preds, sample_weight=mask)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "        loss = self.compute_loss(y=one_hot, y_pred=preds, sample_weight=mask)\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04839be",
   "metadata": {},
   "source": [
    "# Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0fca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
      "\u001b[1m2748572632/2748572632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1469s\u001b[0m 1us/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/LJSpeech-1.1\\\\metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m wavs \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/**/*.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(saveto), recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m id_to_text \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(saveto, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\MUFEEZ\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/LJSpeech-1.1\\\\metadata.csv'"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file(\n",
    "    fname=\"data.tar.gz\",   # ✅ only the file name\n",
    "    origin=\"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
    "    extract=True,\n",
    "    archive_format=\"tar\",\n",
    "    cache_dir=\".\",         # ✅ this controls where it is stored\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34658be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveto = \"./datasets/data_extracted/LJSpeech-1.1\"\n",
    "wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n",
    "\n",
    "id_to_text = {}\n",
    "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        id = line.strip().split(\"|\")[0]\n",
    "        text = line.strip().split(\"|\")[2]\n",
    "        id_to_text[id] = text\n",
    "\n",
    "\n",
    "def get_data(wavs, id_to_text, maxlen=50):\n",
    "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
    "    data = []\n",
    "    for w in wavs:\n",
    "        id = pattern_wav_name.split(w)[-4]\n",
    "        if len(id_to_text[id]) < maxlen:\n",
    "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c84ea",
   "metadata": {},
   "source": [
    "# Preprocess the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40e3022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 34\n"
     ]
    }
   ],
   "source": [
    "class VectorizeChar:\n",
    "    def __init__(self, max_len=50):\n",
    "        self.vocab = (\n",
    "            [\"-\", \"#\", \"<\", \">\"]\n",
    "            + [chr(i + 96) for i in range(1, 27)]\n",
    "            + [\" \", \".\", \",\", \"?\"]\n",
    "        )\n",
    "        self.max_len = max_len\n",
    "        self.char_to_idx = {}\n",
    "        for i, ch in enumerate(self.vocab):\n",
    "            self.char_to_idx[ch] = i\n",
    "\n",
    "    def __call__(self, text):\n",
    "        text = text.lower()\n",
    "        text = text[: self.max_len - 2]\n",
    "        text = \"<\" + text + \">\"\n",
    "        pad_len = self.max_len - len(text)\n",
    "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
    "data = get_data(wavs, id_to_text, max_target_len)\n",
    "vectorizer = VectorizeChar(max_target_len)\n",
    "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
    "\n",
    "\n",
    "def create_text_ds(data):\n",
    "    texts = [_[\"text\"] for _ in data]\n",
    "    text_ds = [vectorizer(t) for t in texts]\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
    "    return text_ds\n",
    "\n",
    "\n",
    "def path_to_audio(path):\n",
    "    # spectrogram using stft\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
    "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
    "    # normalisation\n",
    "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
    "    x = (x - means) / stddevs\n",
    "    audio_len = tf.shape(x)[0]\n",
    "    # padding to 10 seconds\n",
    "    pad_len = 2754\n",
    "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
    "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_audio_ds(data):\n",
    "    flist = [_[\"audio\"] for _ in data]\n",
    "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
    "    audio_ds = audio_ds.map(path_to_audio, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return audio_ds\n",
    "\n",
    "\n",
    "def create_tf_dataset(data, bs=4):\n",
    "    audio_ds = create_audio_ds(data)\n",
    "    text_ds = create_text_ds(data)\n",
    "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
    "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
    "    ds = ds.batch(bs)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "split = int(len(data) * 0.99)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "ds = create_tf_dataset(train_data, bs=64)\n",
    "val_ds = create_tf_dataset(test_data, bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df84e6",
   "metadata": {},
   "source": [
    "# Callbacks to display predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d58fce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 != 0:\n",
    "            return\n",
    "        source = self.batch[\"source\"]\n",
    "        target = self.batch[\"target\"].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-','')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef52d4c",
   "metadata": {},
   "source": [
    "# Learning rate schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e0393f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_lr=0.00001,\n",
    "        lr_after_warmup=0.001,\n",
    "        final_lr=0.00001,\n",
    "        warmup_epochs=15,\n",
    "        decay_epochs=85,\n",
    "        steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\"linear warm up - linear decay\"\"\"\n",
    "        warmup_lr = (\n",
    "            self.init_lr\n",
    "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / self.decay_epochs,\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        epoch = tf.cast(epoch, \"float32\")\n",
    "        return self.calculate_lr(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03a8fd",
   "metadata": {},
   "source": [
    "# Create & train the end-to-end model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f77b6618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:From c:\\Users\\MUFEEZ\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 1.8579target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the in cole t an e the as t the in the in the the the athe athe t ant e athe as t s the s e o the are ce the the an the athede the as t thee t t thacuthe in is e thee itin theas thens te as e then at\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <the in cole t an e the as t the in the in the the the athe athe t ant e athe as t on as s e o the are ce the the an the athede the as t thee t t thacuthe in in e thee itin theas thenthe s te apos the\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <the in cole t an e the as t the in the in the the the athe athe t ant e athe as t s the s e o the are ce the the an the athede the as t thee t t thacuthe in is e thee itin theas thens te as e then at\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <the in cole t an e the as t the in the in the the the athe athe t ant e athe as t on as s e o the are ce the the an the athede the as t thee t t thacuthe in in e thee itin theas thenthe s te apos the\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 3s/step - loss: 1.6655 - val_loss: 1.5824\n",
      "Epoch 2/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - loss: 1.3636 - val_loss: 1.4250\n",
      "Epoch 3/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m749s\u001b[0m 4s/step - loss: 1.3226 - val_loss: 1.4008\n",
      "Epoch 4/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 4s/step - loss: 1.3100 - val_loss: 1.3930\n",
      "Epoch 5/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 4s/step - loss: 1.3036 - val_loss: 1.3852\n",
      "Epoch 6/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - loss: 1.3012target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the se the the the the the the se the se the the se the the the the the the the the the the se the the the the s.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <the se the the the the the the se the se the the se ase ase the the the the the the the the the the the the the the the the se the the sisiof the the the thesinthe thesidenthecenedy.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <the se the se the the the se the se the se the se sinofofofofore the the the the the the the.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <the the the the the the the the the the the the the ase the the the the the the ofof the the the the the the the the the the the the the the the the the the the the the senthe thedy.>\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m957s\u001b[0m 5s/step - loss: 1.2981 - val_loss: 1.3777\n",
      "Epoch 7/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 4s/step - loss: 1.2915 - val_loss: 1.3671\n",
      "Epoch 8/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m768s\u001b[0m 4s/step - loss: 1.2766 - val_loss: 1.3375\n",
      "Epoch 9/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 2s/step - loss: 1.2304 - val_loss: 1.2510\n",
      "Epoch 10/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 2s/step - loss: 1.1748 - val_loss: 1.1941\n",
      "Epoch 11/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.1423target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the secret of the secret of the secret of the secret of the secret of the secretialy.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <the secret secret and the secret and and the secret and the secret and the secret of the secret and the se se se se se se sthese sthe the tente tithesteste titentesthesident tennedy.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <the secret secret of the secret secretial and the secretial and and the secres.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <the secret of the secret of the secret of the secret of the secret of the secret of the secret of the secrese sintintintintintintintintintintentintintintintententinterendent tennedy.>\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 2s/step - loss: 1.1278 - val_loss: 1.1498\n",
      "Epoch 12/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 2s/step - loss: 1.0980 - val_loss: 1.1260\n",
      "Epoch 13/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 2s/step - loss: 1.0807 - val_loss: 1.1010\n",
      "Epoch 14/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 2s/step - loss: 1.0618 - val_loss: 1.0734\n",
      "Epoch 15/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - loss: 1.0437 - val_loss: 1.0580\n",
      "Epoch 16/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.0434target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the secret service of the secret service of the secret secret service.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <secret secret service of the secret secret secret secret secret secret secret secret secret of the secret secrent ofofontit ofof ont tidentidentidentidentiationt.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <is secret secret secret secret secret secret secret secret.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it was not of the secret service of the secret service of the secret service of the president in the secret ontimenthen sintin of of of ofof of of of senthe.>\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 2s/step - loss: 1.0279 - val_loss: 1.0410\n",
      "Epoch 17/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 2s/step - loss: 1.0103 - val_loss: 1.0215\n",
      "Epoch 18/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 2s/step - loss: 0.9914 - val_loss: 1.0052\n",
      "Epoch 19/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 4s/step - loss: 0.9724 - val_loss: 0.9874\n",
      "Epoch 20/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m926s\u001b[0m 5s/step - loss: 0.9519 - val_loss: 0.9687\n",
      "Epoch 21/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 0.9516target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <being the crease informations which informations which informations.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <compressident as more assistant is morest of the president assistant of the president assistant of the president asssitisis t tis tithe titalatatengenthe.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <in as fiest imment of the man assistances the findicates.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it is not the mandard the assassinating the assassinating the assassinative assisance of the protective as and the asss an as as wasss.>\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 4s/step - loss: 0.9311 - val_loss: 0.9476\n",
      "Epoch 22/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 4s/step - loss: 0.9105 - val_loss: 0.9347\n",
      "Epoch 23/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 4s/step - loss: 0.8925 - val_loss: 0.9268\n",
      "Epoch 24/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 5s/step - loss: 0.8763 - val_loss: 0.9156\n",
      "Epoch 25/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 4s/step - loss: 0.8603 - val_loss: 0.9034\n",
      "Epoch 26/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - loss: 0.8629target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the creased informations which was information by the assigned.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <president that that that that that that that that that the president close of the president close of the president clintis tis tice the tite tive te te the titity.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <insting in the many of the many of the many of the many of the many of the many>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it made made made made and been other office and the made and the made and the busing the made and the becauses were on an the the the t the these athe athe thelathellles.>\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m971s\u001b[0m 5s/step - loss: 0.8458 - val_loss: 0.8959\n",
      "Epoch 27/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 3s/step - loss: 0.8342 - val_loss: 0.8921\n",
      "Epoch 28/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 2s/step - loss: 0.8229 - val_loss: 0.8792\n",
      "Epoch 29/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 2s/step - loss: 0.8114 - val_loss: 0.8731\n",
      "Epoch 30/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 2s/step - loss: 0.7998 - val_loss: 0.8667\n",
      "Epoch 31/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 0.8047target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the informations will be informations will building building building building.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <president kelless file assistantive been that that that the president ass morest of the president assistantive assistange titare tide.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <in of the president, find in sistement,>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it made asssandate made asssances no the recess of the proveral office dessiveral office desident in dexas no the recesin den d den d desesin desen d des.>\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 3s/step - loss: 0.7881 - val_loss: 0.8623\n",
      "Epoch 32/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 4s/step - loss: 0.7775 - val_loss: 0.8586\n",
      "Epoch 33/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 2s/step - loss: 0.7695 - val_loss: 0.8590\n",
      "Epoch 34/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 2s/step - loss: 0.7627 - val_loss: 0.8574\n",
      "Epoch 35/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 3s/step - loss: 0.7553 - val_loss: 0.8522\n",
      "Epoch 36/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 0.7597target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the information for made by creass information will be information will be information.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <conting the president kell assistant the president kell assignerated suggest to convictive assistant the president subjectien thare contied contide the tsides onthem>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <in the assal filenging in is president,>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it made and been officient in the recoverlmating officient which as no the profice debaus and been office debt debasing the over of the profid of derenerellllllllllendesout>\n",
      "\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 3s/step - loss: 0.7434 - val_loss: 0.8385\n",
      "Epoch 37/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 2s/step - loss: 0.7327 - val_loss: 0.8277\n",
      "Epoch 38/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 3s/step - loss: 0.7208 - val_loss: 0.8154\n",
      "Epoch 39/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1296s\u001b[0m 6s/step - loss: 0.7095 - val_loss: 0.8082\n",
      "Epoch 40/40\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1512s\u001b[0m 7s/step - loss: 0.7006 - val_loss: 0.8085\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_ds))\n",
    "\n",
    "# The vocabulary to convert predicted indices into characters\n",
    "idx_to_char = vectorizer.get_vocabulary()\n",
    "display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=200,\n",
    "    num_head=2,\n",
    "    num_feed_forward=400,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=4,\n",
    "    num_layers_dec=1,\n",
    "    num_classes=34,\n",
    ")\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    label_smoothing=0.1,\n",
    ")\n",
    "\n",
    "learning_rate = CustomSchedule(\n",
    "    init_lr=0.00001,\n",
    "    lr_after_warmup=0.001,\n",
    "    final_lr=0.00001,\n",
    "    warmup_epochs=15,\n",
    "    decay_epochs=85,\n",
    "    steps_per_epoch=len(ds),\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb], epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce070dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"transformer_speech_to_text.keras\", include_optimizer=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98878bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
